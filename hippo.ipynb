{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiPPO Matrices\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Device: cpu\n",
      "MPS enabled: False\n"
     ]
    }
   ],
   "source": [
    "#from functools import partial\n",
    "#from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "#from einops import rearrange, reduce, repeat\n",
    "import math\n",
    "#import requests\n",
    "from scipy import linalg as la\n",
    "from scipy import signal\n",
    "from scipy import special as ss\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"The Device: {device}\")\n",
    "\n",
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Device: cpu\n"
     ]
    }
   ],
   "source": [
    "## import packages\n",
    "import math\n",
    "\n",
    "import requests\n",
    "\n",
    "from scipy import linalg as la\n",
    "from scipy import signal\n",
    "from scipy import special as ss\n",
    "\n",
    "from src.data.process import moving_window, rolling_window\n",
    "#import modules \n",
    "from src.models.hippo.gu_transition import GuTransMatrix\n",
    "from src.models.hippo.unroll import (basis, measure, variable_unroll_matrix,\n",
    "                                     variable_unroll_matrix_sequential)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"The Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hippo NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIPPO_LEGS(nn.Module):\n",
    "    \"\"\"Hippo class utilizing legs polynomial\"\"\"\n",
    "\n",
    "    def __init__(self, N, gbt_alpha = 0.5, maxlength = 1024):\n",
    "        super(HIPPO_LEGS, self).__init__()\n",
    "        self.N = N\n",
    "        self.gbt_alpha = gbt_alpha\n",
    "        self.maxlength = maxlength\n",
    "        \n",
    "    def compute_A(self, n, k):\n",
    "        '''\n",
    "        Computes the values for the HiPPO A matrix row by column \n",
    "        using the piecewise equation on p. 31 eq. 29:\n",
    "                (2n+1)^{1/2} (2k+ 1)^{1/2} if n > k  \n",
    "        A_{nk} = n+1                       if n = k,\n",
    "                 0                         if n < k\n",
    "        , where n represents the row and k the columns. \n",
    "        \n",
    "        Input:\n",
    "            n (int):\n",
    "                nth row of a square matrix of size N\n",
    "            k (int):\n",
    "                kth column of a square matrix of size N\n",
    "        \n",
    "        Returns:\n",
    "            Values (float):\n",
    "            Individual values for the elements in the A matrix. \n",
    "        '''\n",
    "        if n > k:\n",
    "            val = np.sqrt(2 * n + 1, dtype = np.float32) * np.sqrt(2 * k + 1, dtype = np.float32)\n",
    "        if n == k:\n",
    "            val = n + 1 \n",
    "        if n < k:\n",
    "            val = 0\n",
    "        return val\n",
    "\n",
    "    def compute_B(self, n):\n",
    "        '''\n",
    "        Computes the values for the HiPPO B matrix row by column \n",
    "        using the piecewise equation on p. 31 eq. 29:\n",
    "        B_{n} = (2n+1)^{1/2}\n",
    "        \n",
    "        Input:\n",
    "            n (int):\n",
    "                nth column of a square matrix of size N.\n",
    "            \n",
    "        Returns:\n",
    "            Values (float):\n",
    "            Individual values for the elements in the B matrix.\n",
    "            The next hidden state (aka coefficients representing the function, f(t))\n",
    "        '''\n",
    "        val = np.sqrt(2 * n + 1, dtype = np.float32)\n",
    "        return val\n",
    "\n",
    "    def get_A_and_B(self, N):\n",
    "        '''\n",
    "        Creates the HiPPO A and B matrix given the size N along a single axis of \n",
    "        a square matrix.\n",
    "        \n",
    "        Input: \n",
    "            N (int):\n",
    "            Size N of a square matrix along a single axis.\n",
    "        \n",
    "        Returns: \n",
    "            A (np.ndarray)\n",
    "                shape: (N,N)\n",
    "                the HiPPO A matrix.\n",
    "            B (np.ndarray)\n",
    "                shape: (N,):\n",
    "                The HiPPO B matrix.\n",
    "        '''\n",
    "        A = np.zeros((self.N, self.N), dtype = np.float32)\n",
    "        B = np.zeros((self.N, 1), dtype = np.float32)\n",
    "\n",
    "        for n in range(A.shape[0]):\n",
    "            B[n][0] = self.compute_B(n = n)\n",
    "            for k in range(A.shape[1]):\n",
    "                A[n, k] = self.compute_A(n = n , k = k)\n",
    "\n",
    "        return A  * -1, B\n",
    "    \n",
    "    def generalized_bilinear_transform(self, A, B, t, gbt_alpha):\n",
    "        '''\n",
    "        Performs the generalised bilinaer transform from p. 21 eq.13:\n",
    "        c(t + ∆t) − ∆tαAc(t + ∆t) = (I + ∆t(1 − α)A)c(t) + ∆tBf(t)\n",
    "        c(t + ∆t) = (I − ∆tαA)^{−1} (I + ∆t(1 − α)A)c(t) + ∆t(I − ∆tαA)^{−1}Bf(t).\n",
    "        on the HiPPO matrix A and B, transforming them. \n",
    "        Input:\n",
    "            A (np.ndarray):\n",
    "                shape: (N, N)\n",
    "                the HiPPO A matrix\n",
    "            B (np.ndarray):\n",
    "                shape: (N,)\n",
    "                the HiPPO B matrix\n",
    "            Timestep t = 1/input length at t (int):\n",
    "        \n",
    "        Output:\n",
    "            GBTA (np.array):\n",
    "                shape: (N, N)\n",
    "                Transformed HiPPO A matrix.\n",
    "            \n",
    "            GBTB (np.array):\n",
    "                shape: (N,)\n",
    "                Transformed HiPPO B matrix.\n",
    "        '''\n",
    "        I = np.eye(A.shape[0], dtype = np.float32)\n",
    "        delta_t = 1 / t\n",
    "        EQ13_p1 = I - (delta_t * gbt_alpha * A)\n",
    "        EQ13_p2 = I + (delta_t * (1 - gbt_alpha) * A)\n",
    "        EQA = np.linalg.lstsq(EQ13_p1, EQ13_p2, rcond = None)[0]\n",
    "        EQB =  np.linalg.lstsq(EQ13_p1, (delta_t * B), rcond = None)[0]         \n",
    "        return EQA, EQB\n",
    "    \n",
    "    def get_stacked_GBT(self):\n",
    "        A, B = self.get_A_and_B(self.N)\n",
    "        GBTA_stacked = np.empty((self.maxlength, self.N, self.N), dtype=np.float32)\n",
    "        GBTB_stacked = np.empty((self.maxlength, self.N, 1), dtype=np.float32)\n",
    "        \n",
    "        for t in range(1, self.maxlength + 1):\n",
    "            GBTA, GBTB = self.generalized_bilinear_transform(A = A, B = B, t = t, gbt_alpha = self.gbt_alpha)\n",
    "            GBTA_stacked[t-1] = GBTA\n",
    "            GBTB_stacked[t-1] = GBTB\n",
    "            \n",
    "        return GBTA_stacked, GBTB_stacked\n",
    "    \n",
    "    def discrete_hippo_operator(self, A, B, inputs, c_t =  None):\n",
    "        '''\n",
    "        Input:\n",
    "            A (np.ndarray):\n",
    "                shape: (N, N)\n",
    "                the discretized A matrix\n",
    "            B (np.ndarray):\n",
    "                shape: (N, 1)\n",
    "                the discretized B matrix\n",
    "            c_t (np.ndarray):\n",
    "                shape: (batch size, input length, N)\n",
    "                the initial hidden state\n",
    "            inputs (torch.tensor):\n",
    "                shape: (batch size, maxlength)\n",
    "                the input sequence\n",
    "        Returns:\n",
    "            The next hidden state (aka coefficients representing the function, f(t))\n",
    "        '''\n",
    "        batchsize = inputs.shape[0]\n",
    "        L = inputs.shape[1]\n",
    "\n",
    "        # Change input shape from (batch size, max length)\n",
    "        # to (max length, batch size, max length)\n",
    "        # note that max length can also be regarded as the length of the signal\n",
    "        inputs = torch.tensor(inputs)\n",
    "        inputs = inputs.T.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        lst = []\n",
    "        \n",
    "        if c_t is None:\n",
    "            c_t = np.zeros((batchsize, 1, self.N), dtype = np.float32)\n",
    "            \n",
    "        for t, f_t in enumerate(inputs):\n",
    "            \n",
    "            #part_1 = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float())\n",
    "            #part_2 = np.squeeze(B[t], -1) * f_t.numpy()\n",
    "            #c_t = part_1 + part_2\n",
    "            \n",
    "            c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n",
    "            lst.append(c_t)\n",
    "        return np.stack(lst, axis = 0, dtype = np.float32)\n",
    "    \n",
    "    def reconstruct(self, c, B):\n",
    "        vals = np.linspace(0.0, 1.0, self.maxlength)\n",
    "        # If clause for supporting use of batched raw signal \n",
    "        # with batch information of shape [batchsize, maxlength] \n",
    "        if len(c.shape) == 4:\n",
    "            # c shape from: [maxlength, batchsize, 1, N_coeffs]\n",
    "            # 1st move to: [batchsize, maxlength, 1, N_coeffs]\n",
    "            # 2nd move to: [batchsize, maxlength, N_coeffs, 1]\n",
    "            c = np.moveaxis(c, 0, 1)\n",
    "            c = np.moveaxis(c, 2, 3)\n",
    "        \n",
    "        eval_mat = (B * np.float32(ss.eval_legendre(np.expand_dims(np.arange(self.N, dtype = np.float32), -1), 2 * vals - 1))).T\n",
    "        recon = eval_mat @ np.float32(c)\n",
    "        return recon\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # 1.Compute B, GBTA and GBTA matrices\n",
    "        # B is needed in 3. for the reconstruction\n",
    "        # GBTA and GBTA is needed for coefficents c\n",
    "        _, B = self.get_A_and_B(N = self.N)\n",
    "        GBTA, GBTB = self.get_stacked_GBT()\n",
    "        # 2.Compute coefficents c\n",
    "        c = self.discrete_hippo_operator(A = GBTA, B = GBTB, inputs = inputs, c_t = None)\n",
    "        # 3. Compute reconstruction r\n",
    "        r =  self.reconstruct(c = c, B = B)\n",
    "        return c, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIPPO_LEGS(nn.Module):\n",
    "    \"\"\"Hippo class utilizing legs polynomial\"\"\"\n",
    "\n",
    "    def __init__(self, N, gbt_alpha = 0.5, maxlength = 1024):\n",
    "        super(HIPPO_LEGS, self).__init__()\n",
    "        self.N = N\n",
    "        self.gbt_alpha = gbt_alpha\n",
    "        self.maxlength = maxlength\n",
    "        \n",
    "    def compute_A(self, n, k):\n",
    "        '''\n",
    "        Computes the values for the HiPPO A matrix row by column \n",
    "        using the piecewise equation on p. 31 eq. 29:\n",
    "                (2n+1)^{1/2} (2k+ 1)^{1/2} if n > k  \n",
    "        A_{nk} = n+1                       if n = k,\n",
    "                 0                         if n < k\n",
    "        , where n represents the row and k the columns. \n",
    "        \n",
    "        Input:\n",
    "            n (int):\n",
    "                nth row of a square matrix of size N\n",
    "            k (int):\n",
    "                kth column of a square matrix of size N\n",
    "        \n",
    "        Returns:\n",
    "            Values (float):\n",
    "            Individual values for the elements in the A matrix. \n",
    "        '''\n",
    "        if n > k:\n",
    "            val = np.sqrt(2 * n + 1, dtype = np.float32) * np.sqrt(2 * k + 1, dtype = np.float32)\n",
    "        if n == k:\n",
    "            val = n + 1 \n",
    "        if n < k:\n",
    "            val = 0\n",
    "        return val\n",
    "\n",
    "    def compute_B(self, n):\n",
    "        '''\n",
    "        Computes the values for the HiPPO B matrix row by column \n",
    "        using the piecewise equation on p. 31 eq. 29:\n",
    "        B_{n} = (2n+1)^{1/2}\n",
    "        \n",
    "        Input:\n",
    "            n (int):\n",
    "                nth column of a square matrix of size N.\n",
    "            \n",
    "        Returns:\n",
    "            Values (float):\n",
    "            Individual values for the elements in the B matrix.\n",
    "            The next hidden state (aka coefficients representing the function, f(t))\n",
    "        '''\n",
    "        val = np.sqrt(2 * n + 1, dtype = np.float32)\n",
    "        return val\n",
    "\n",
    "    def get_A_and_B(self, N):\n",
    "        '''\n",
    "        Creates the HiPPO A and B matrix given the size N along a single axis of \n",
    "        a square matrix.\n",
    "        \n",
    "        Input: \n",
    "            N (int):\n",
    "            Size N of a square matrix along a single axis.\n",
    "        \n",
    "        Returns: \n",
    "            A (np.ndarray)\n",
    "                shape: (N,N)\n",
    "                the HiPPO A matrix.\n",
    "            B (np.ndarray)\n",
    "                shape: (N,):\n",
    "                The HiPPO B matrix.\n",
    "        '''\n",
    "        A = np.zeros((self.N, self.N), dtype = np.float32)\n",
    "        B = np.zeros((self.N, 1), dtype = np.float32)\n",
    "\n",
    "        for n in range(A.shape[0]):\n",
    "            B[n][0] = self.compute_B(n = n)\n",
    "            for k in range(A.shape[1]):\n",
    "                A[n, k] = self.compute_A(n = n , k = k)\n",
    "\n",
    "        return A  * -1, B\n",
    "    \n",
    "    def generalized_bilinear_transform(self, A, B, t, gbt_alpha):\n",
    "        '''\n",
    "        Performs the generalised bilinaer transform from p. 21 eq.13:\n",
    "        c(t + ∆t) − ∆tαAc(t + ∆t) = (I + ∆t(1 − α)A)c(t) + ∆tBf(t)\n",
    "        c(t + ∆t) = (I − ∆tαA)^{−1} (I + ∆t(1 − α)A)c(t) + ∆t(I − ∆tαA)^{−1}Bf(t).\n",
    "        on the HiPPO matrix A and B, transforming them. \n",
    "        Input:\n",
    "            A (np.ndarray):\n",
    "                shape: (N, N)\n",
    "                the HiPPO A matrix\n",
    "            B (np.ndarray):\n",
    "                shape: (N,)\n",
    "                the HiPPO B matrix\n",
    "            Timestep t = 1/input length at t (int):\n",
    "        \n",
    "        Output:\n",
    "            GBTA (np.array):\n",
    "                shape: (N, N)\n",
    "                Transformed HiPPO A matrix.\n",
    "            \n",
    "            GBTB (np.array):\n",
    "                shape: (N,)\n",
    "                Transformed HiPPO B matrix.\n",
    "        '''\n",
    "        I = np.eye(A.shape[0], dtype = np.float32)\n",
    "        delta_t = 1 / t\n",
    "        EQ13_p1 = I - (delta_t * gbt_alpha * A)\n",
    "        EQ13_p2 = I + (delta_t * (1 - gbt_alpha) * A)\n",
    "        EQA = np.linalg.lstsq(EQ13_p1, EQ13_p2, rcond = None)[0]\n",
    "        EQB =  np.linalg.lstsq(EQ13_p1, (delta_t * B), rcond = None)[0]         \n",
    "        return EQA, EQB\n",
    "    \n",
    "    def get_stacked_GBT(self):\n",
    "        A, B = self.get_A_and_B(self.N)\n",
    "        GBTA_stacked = np.empty((self.maxlength, self.N, self.N), dtype=np.float32)\n",
    "        GBTB_stacked = np.empty((self.maxlength, self.N, 1), dtype=np.float32)\n",
    "        \n",
    "        for t in range(1, self.maxlength + 1):\n",
    "            GBTA, GBTB = self.generalized_bilinear_transform(A = A, B = B, t = t, gbt_alpha = self.gbt_alpha)\n",
    "            GBTA_stacked[t-1] = GBTA\n",
    "            GBTB_stacked[t-1] = GBTB\n",
    "            \n",
    "        return GBTA_stacked, GBTB_stacked\n",
    "    \n",
    "    def discrete_hippo_operator(self, A, B, inputs, c_t =  None):\n",
    "        '''\n",
    "        Input:\n",
    "            A (np.ndarray):\n",
    "                shape: (N, N)\n",
    "                the discretized A matrix\n",
    "            B (np.ndarray):\n",
    "                shape: (N, 1)\n",
    "                the discretized B matrix\n",
    "            c_t (np.ndarray):\n",
    "                shape: (batch size, input length, N)\n",
    "                the initial hidden state\n",
    "            inputs (torch.tensor):\n",
    "                shape: (batch size, maxlength)\n",
    "                the input sequence\n",
    "        Returns:\n",
    "            The next hidden state (aka coefficients representing the function, f(t))\n",
    "        '''\n",
    "        batchsize = inputs.shape[0]\n",
    "        L = inputs.shape[1]\n",
    "        print(\"-------------Input------------\")\n",
    "        print(\"Ramen inputs shape:\", inputs.shape)\n",
    "        # Change input shape from (batch size, max length)\n",
    "        # to (max length, batch size, max length)\n",
    "        # note that max length can also be regarded as the length of the signal\n",
    "        inputs = torch.tensor(inputs)\n",
    "        inputs = inputs.T.unsqueeze(-1).unsqueeze(-1)\n",
    "        print(\"Ramen inputs shape:\", inputs.shape)\n",
    "        lst = []\n",
    "        \n",
    "        if c_t is None:\n",
    "            c_t = np.zeros((batchsize, 1, self.N), dtype = np.float32)\n",
    "            \n",
    "        print(\"-------------Init------------\")\n",
    "        print(\"Ramen coef c shape:\", c_t.shape)\n",
    "        print(\"-------------Init------------\")\n",
    "        switch = True\n",
    "        for t, f_t in enumerate(inputs):\n",
    "            \n",
    "            #part_1 = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float())\n",
    "            #part_2 = np.squeeze(B[t], -1) * f_t.numpy()\n",
    "            #c_t = part_1 + part_2\n",
    "            \n",
    "            c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n",
    "            if switch == True:\n",
    "                print(\"----------Ramen F Linear:----------\")\n",
    "                print(\"Ramen part1 shape:\", F.linear(torch.tensor(c_t).float(), torch.tensor(A[t])).shape)\n",
    "                print(\"Ramen part2  shape:\", (np.squeeze(B[t], -1) * f_t.numpy()).shape)\n",
    "                print(\"Ramen A stacked  shape:\", A[t].shape)\n",
    "                print(\"Ramen B stacked  shape:\", np.squeeze(B[t], -1).shape)\n",
    "                print(\"Ramen input [f] shape:\", f_t.shape)\n",
    "                print(\"Ramen Coef  c shape:\", c_t.shape)\n",
    "                switch = False\n",
    "            #print(\"our c_t:\", c_t.shape)\n",
    "            lst.append(c_t)\n",
    "        return np.stack(lst, axis = 0, dtype = np.float32)\n",
    "    \n",
    "    def reconstruct(self, c, B):\n",
    "        vals = np.linspace(0.0, 1.0, self.maxlength)\n",
    "        print(\"----------Ramen Reconstruction part:----------\")\n",
    "        # If clause for supporting use of batched raw signal \n",
    "        # with batch information of shape [batchsize, maxlength] \n",
    "        if len(c.shape) == 4:\n",
    "            # c shape from: [maxlength, batchsize, 1, N_coeffs]\n",
    "            # 1st move to: [batchsize, maxlength, 1, N_coeffs]\n",
    "            # 2nd move to: [batchsize, maxlength, N_coeffs, 1]\n",
    "            c = np.moveaxis(c, 0, 1)\n",
    "            print(\"Ramen Coefs stacked shape:\", c.shape)\n",
    "            c = np.moveaxis(c, 2, 3)\n",
    "            print(\"Ramen Coefs stacked shape:\", c.shape)\n",
    "        \n",
    "        eval_mat = (B * np.float32(ss.eval_legendre(np.expand_dims(np.arange(self.N, dtype = np.float32), -1), 2 * vals - 1))).T\n",
    "        recon = eval_mat @ np.float32(c)\n",
    "        print(\"Ramen Eval mat shape:\", eval_mat.shape)\n",
    "        print(\"Ramen Coefs stacked shape:\", c.shape)\n",
    "        print(\"Ramen Recon shape:\", recon.shape)\n",
    "        print(\"----------------------------------------\")\n",
    "        return recon\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # 1.Compute B, GBTA and GBTA matrices\n",
    "        # B is needed in 3. for the reconstruction\n",
    "        # GBTA and GBTA is needed for coefficents c\n",
    "        _, B = self.get_A_and_B(N = self.N)\n",
    "        GBTA, GBTB = self.get_stacked_GBT()\n",
    "        # 2.Compute coefficents c\n",
    "        c = self.discrete_hippo_operator(A = GBTA, B = GBTB, inputs = inputs, c_t = None)\n",
    "        # 3. Compute reconstruction r\n",
    "        r =  self.reconstruct(c = c, B = B)\n",
    "        return c, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO_LSI(nn.Module):\n",
    "    \"\"\"Vanilla HiPPO-LegS model (scale invariant instead of time invariant)\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        method=\"legs\",\n",
    "        max_length=1024,\n",
    "        discretization=0.5,\n",
    "        lambda_n=1.0,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        max_length: maximum sequence length\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        matrices = GuTransMatrix(\n",
    "            N=N, measure=method, lambda_n=lambda_n, alpha=alpha, beta=beta\n",
    "        )\n",
    "        A = np.asarray(matrices.A, dtype=np.float32)\n",
    "        B = np.asarray(matrices.B, dtype=np.float32)\n",
    "        B = B.squeeze(-1)\n",
    "\n",
    "        A_stacked = np.empty((max_length, N, N), dtype=A.dtype)\n",
    "        B_stacked = np.empty((max_length, N), dtype=B.dtype)\n",
    "\n",
    "        for t in range(1, max_length + 1):\n",
    "            At = A / t\n",
    "            Bt = B / t\n",
    "            if discretization == 0.0:  # forward\n",
    "                A_stacked[t - 1] = np.eye(N) + At\n",
    "                B_stacked[t - 1] = Bt\n",
    "            elif discretization == 1.0:  # backward\n",
    "                A_stacked[t - 1] = la.solve_triangular(\n",
    "                    np.eye(N) - At, np.eye(N), lower=True\n",
    "                )\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, Bt, lower=True)\n",
    "            elif discretization == 0.5:  # bilinear\n",
    "                # A_stacked[t - 1] = la.solve_triangular(\n",
    "                #     np.eye(N) - At / 2, np.eye(N) + At / 2, lower=True\n",
    "                # )\n",
    "                # B_stacked[t - 1] = la.solve_triangular(\n",
    "                #     np.eye(N) - At / 2, Bt, lower=True\n",
    "                # )\n",
    "                alpha = 0.5\n",
    "                A_stacked[t - 1] = np.linalg.lstsq(\n",
    "                    np.eye(N) - (At * alpha), np.eye(N) + (At * alpha), rcond=None\n",
    "                )[\n",
    "                    0\n",
    "                ]  # TODO: Referencing this: https://stackoverflow.com/questions/64527098/numpy-linalg-linalgerror-singular-matrix-error-when-trying-to-solve\n",
    "                B_stacked[t - 1] = np.linalg.lstsq(\n",
    "                    np.eye(N) - (At * alpha), Bt, rcond=None\n",
    "                )[0]\n",
    "                \n",
    "            else:  # ZOH\n",
    "                A_stacked[t - 1] = la.expm(A * (math.log(t + 1) - math.log(t)))\n",
    "                # A_stacked[t - 1] = la.expm(At)\n",
    "                B_stacked[t - 1] = la.solve_triangular(\n",
    "                    A, A_stacked[t - 1] @ B - B, lower=True\n",
    "                )\n",
    "                \n",
    "                # A_stacked[t - 1] = la.expm(At)\n",
    "                # B_stacked[t - 1] = la.inv(A) @ (la.expm(At) - np.eye(A.shape[0])) @ B\n",
    "                \n",
    "                \n",
    "        # self.register_buffer('A_stacked', torch.Tensor(A_stacked)) # (max_length, N, N)\n",
    "        # self.register_buffer('B_stacked', torch.Tensor(B_stacked)) # (max_length, N)\n",
    "        \n",
    "        self.A_stacked = torch.Tensor(A_stacked.copy())  # (max_length, N, N)\n",
    "        self.B_stacked = torch.Tensor(B_stacked.copy())  # (max_length, N)\n",
    "\n",
    "        vals = np.linspace(0.0, 1.0, max_length)\n",
    "        \n",
    "        self.eval_matrix = torch.from_numpy(\n",
    "            np.asarray(\n",
    "                ((B[:, None] * ss.eval_legendre(np.arange(N)[:, None], 2 * vals - 1)).T)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, fast=False):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "        print(\"-------------Input------------\")\n",
    "        print(\"Gu inputs shape:\", inputs.shape)\n",
    "        L = inputs.shape[0]\n",
    "        print(\"Gu L :\", L)\n",
    "        inputs = inputs.unsqueeze(-1)\n",
    "        print(\"Gu inputs shape unsqueeze :\", inputs.shape)\n",
    "        u = torch.transpose(inputs, 0, -2)\n",
    "        print(\"Gu signal u transpose :\", u.shape)\n",
    "        print(\"Gu self.B_stacked shape :\", self.B_stacked.shape)\n",
    "        print(\"Gu self.B_stacked[:L] shape:\", self.B_stacked[:L].shape)\n",
    "        u = u * self.B_stacked[:L]\n",
    "        print(\"Gu signal u mult self.B_stacked[:L] shape:\", u.shape)\n",
    "        u = torch.transpose(u, 0, -2)  # (length, ..., N)\n",
    "        print(\"Gu signal u transpose 2:\", u.shape)\n",
    "        if fast:\n",
    "            result = variable_unroll_matrix(self.A_stacked[:L], u)\n",
    "            return result\n",
    "\n",
    "        c = torch.zeros(u.shape[1:]).to(inputs)\n",
    "        print(\"Gu c zeros:\", c.shape)\n",
    "        cs = []\n",
    "        for t, f in enumerate(inputs):\n",
    "            part1 = F.linear(c, self.A_stacked[t])\n",
    "            #print(\"Gu f t shape \",f_t.numpy().shape)\n",
    "            part2 = self.B_stacked[t] * f\n",
    "            c = part1 + part2\n",
    "            print(\"----------Gu F Linear:----------\")\n",
    "            print(\"Gu part1 shape:\", F.linear(c, self.A_stacked[t]).shape)\n",
    "            print(\"Gu part2  shape:\", part2.shape)\n",
    "            print(\"Gu A stacked  shape:\", self.A_stacked[t].shape)\n",
    "            print(\"Gu B stacked  shape:\", self.B_stacked[t].shape)\n",
    "            print(\"Gu input [f] shape:\", f.shape)\n",
    "            print(\"Gu Coef c shape:\", c.shape)\n",
    "            cs.append(c)\n",
    "        print(\"Gu Coef c stacked shape:\", torch.stack(cs, dim=0).shape)\n",
    "        return torch.stack(cs, dim=0)\n",
    "    \n",
    "    def reconstruct(self, c):\n",
    "        a = self.eval_matrix.to(c) @ c.unsqueeze(-1)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Hippo A and B Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init HIPPO LEG S\n",
    "def test_LegS(hippo, N):\n",
    "    A, B = hippo.get_A_and_B(N=N)\n",
    "    gu_legs_matrices = GuTransMatrix(N=N, measure=\"legs\")\n",
    "    gu_A, gu_B = gu_legs_matrices.A, gu_legs_matrices.B\n",
    "    \n",
    "    assert A.shape==gu_A.shape, f\"Shape mismatch between target {gu_A.shape} and hippo A matrix {A.shape}.\"\n",
    "    print(f\"Shape between target and computed hippo A matrix are equal:\\n{gu_A.shape==A.shape}\")\n",
    "    assert B.shape==gu_B.shape, f\"Shape mismatch between target {gu_B.shape} and hippo B matrix {B.shape}.\"\n",
    "    print(f\"Shape between target and computed hippo B matrix are equal:\\n{gu_B.shape==B.shape}\")\n",
    "    assert np.allclose(A, gu_A), f\"Hippo A matrix values between target and computed are not equal:\\n{np.allclose(A, gu_A)}\"\n",
    "    print(f\"Hippo A matrix values between target and computed are equal:\\n{np.allclose(A, gu_A)}\")\n",
    "    assert np.allclose(B, gu_B), f\"Hippo B matrix values between target and computed are not equal:\\n{np.allclose(B, gu_B)}\"\n",
    "    print(f\"Hippo B matrix values between target and computed are equal:\\n{np.allclose(B, gu_B)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape between target and computed hippo A matrix are equal:\n",
      "True\n",
      "Shape between target and computed hippo B matrix are equal:\n",
      "True\n",
      "Hippo A matrix values between target and computed are equal:\n",
      "True\n",
      "Hippo B matrix values between target and computed are equal:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "test_LegS(hippo=HIPPO_LEGS(N=10), N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Hippo GBT Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(batch_size = 16, data_size = 784, input_size = 28):\n",
    "    seed = 1701\n",
    "    x = torch.randint(0, 255, (batch_size, data_size))\n",
    "    x = (x - torch.min(x)) / (torch.max(x) - torch.min(x))\n",
    "    # Torch docs: torch.tensor.unfold(starting dim, window_size, step_size) \n",
    "    #x = x.unfold(1, input_size, 1) \n",
    "    return x\n",
    "\n",
    "batch_size = 2\n",
    "data_size = 4\n",
    "input_size = 1\n",
    "    \n",
    "N = 2\n",
    "L = data_size\n",
    "    \n",
    "gen_data = gen_batch(\n",
    "        batch_size=batch_size, \n",
    "        data_size=data_size, \n",
    "        input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_GBT(the_measure=\"legs\", lambda_n=1.0, gbt_alpha=0.5, discretization=0.5, N=50):\n",
    "    batch_size = 16\n",
    "    data_size = 256\n",
    "    input_size = 1\n",
    "    \n",
    "    L = data_size\n",
    "    \n",
    "    x_np = gen_batch( \n",
    "        batch_size=batch_size, \n",
    "        data_size=data_size, \n",
    "        input_size=input_size\n",
    "    )\n",
    "    print(x_np.shape)\n",
    "    \n",
    "    print(f\"Creating Gu's HiPPO-{the_measure} LSI model with {gbt_alpha} transform\")\n",
    "    gu_hippo_lsi = HiPPO_LSI(\n",
    "        N=N,\n",
    "        method=\"legs\",\n",
    "        max_length=L,\n",
    "        discretization=discretization,\n",
    "        lambda_n=lambda_n,\n",
    "        alpha=0.0,\n",
    "        beta=1.0\n",
    "    )  # The Gu's\n",
    "        \n",
    "    print(f\"Creating HiPPO-{the_measure} LTI model with {gbt_alpha} transform\")    \n",
    "    hippo_lsi = HIPPO_LEGS(N=N, gbt_alpha = gbt_alpha)\n",
    "\n",
    "    print(f\"Testing for correct LTI GBT matrices for HiPPO-{the_measure}\")\n",
    "    test_LSI_GBT(\n",
    "        hippo=hippo_lsi, \n",
    "        gu_hippo=gu_hippo_lsi,\n",
    "        alpha=gbt_alpha, N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our hippo, gu hippo, A, B matrix, random input, alpha\n",
    "# def test_LSI_GBT(hippo, gu_hippo, A, B, random_input, alpha=0.5):\n",
    "def test_LSI_GBT(hippo, gu_hippo, alpha=0.5, N = 3):\n",
    "    gen_data = gen_batch(\n",
    "        batch_size=batch_size, \n",
    "        data_size=data_size, \n",
    "        input_size=input_size\n",
    "    )\n",
    "    \n",
    "    GBT_A, GBT_B = hippo.get_stacked_GBT()\n",
    "    L = gen_data.shape[1]\n",
    "    for i in range(1, L+1):\n",
    "\n",
    "        gu_GBT_A, gu_GBT_B = (\n",
    "            np.asarray(gu_hippo.A_stacked[i-1], dtype=np.float32),\n",
    "            np.expand_dims(np.asarray(gu_hippo.B_stacked[i-1], dtype=np.float32), axis=1),\n",
    "        )\n",
    "        print(f\"GBT_A: {np.allclose(GBT_A[i-1], gu_GBT_A, rtol=1e-04, atol=1e-04)}\")\n",
    "        print(f\"GBT_B: {np.allclose(GBT_B[i-1], gu_GBT_B, rtol=1e-04, atol=1e-04)}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256])\n",
      "Creating Gu's HiPPO-legs LSI model with 0.5 transform\n",
      "Creating HiPPO-legs LTI model with 0.5 transform\n",
      "Testing for correct LTI GBT matrices for HiPPO-legs\n",
      "GBT_A: True\n",
      "GBT_B: True\n",
      "\n",
      "GBT_A: True\n",
      "GBT_B: True\n",
      "\n",
      "GBT_A: True\n",
      "GBT_B: True\n",
      "\n",
      "GBT_A: True\n",
      "GBT_B: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_GBT(the_measure=\"legs\", lambda_n=1.0, gbt_alpha=0.5, discretization=0.5, N =4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Hippo operation for Coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hippo_operator(N=2, batch_size=2, data_size=4, input_size=1):\n",
    "    gu_hippo = HiPPO_LSI(N=N, method=\"legs\", max_length=1000, discretization=1.0, lambda_n=1.0, alpha=0.5, beta=1.0)\n",
    "    hippo = HIPPO_LEGS(N=N, gbt_alpha=1.0)\n",
    "    inp = gen_batch(batch_size = batch_size, data_size=data_size, input_size=input_size)\n",
    "    GBTA, GBTB = hippo.get_stacked_GBT()\n",
    "    gu_c = gu_hippo(inp, fast=False)\n",
    "    print(\"------Gu----------\")\n",
    "    print(\"gu c\",gu_c)\n",
    "    print(\"gu c shape \",gu_c.shape)\n",
    "    our_c = hippo.discrete_hippo_operator(A=GBTA, B=GBTB, inputs=inp, c_t=None)\n",
    "    print(\"------Our----------\")\n",
    "    print(\"our c shape\",our_c.shape)\n",
    "    our_c = np.moveaxis(our_c, 0, 1)\n",
    "    print(\"our c shape\",our_c.shape)\n",
    "    our_c = np.moveaxis(our_c, 2, 3)\n",
    "    print(\"our c shape\",our_c.shape)\n",
    "    #our_c = our_c.squeeze(-1)\n",
    "    print(our_c)\n",
    "    assert gu_c.shape==our_c.shape, f\"Shape mismatch between target {gu_c.shape} and computed coefficent matrix {our_c.shape}.\"\n",
    "    print(f\"Shape between target and computed coefficen matrix are equal:\\n{gu_c.shape==our_c.shape}\")\n",
    "    \n",
    "    assert np.allclose(gu_c, np.float32(our_c), rtol=1e-04, atol=1e-04), f\"Mismatch between target and computed coefficent values\"\n",
    "    print(f\"Coeffcient values between target and computed are equal:\\n{np.allclose(gu_c, np.float32(our_c), rtol=1e-04, atol=1e-04)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "Gu inputs shape: torch.Size([2, 512])\n",
      "Gu L : 2\n",
      "Gu inputs shape unsqueeze : torch.Size([2, 512, 1])\n",
      "Gu signal u transpose : torch.Size([512, 2, 1])\n",
      "Gu self.B_stacked shape : torch.Size([1000, 10])\n",
      "Gu self.B_stacked[:L] shape: torch.Size([2, 10])\n",
      "Gu signal u mult self.B_stacked[:L] shape: torch.Size([512, 2, 10])\n",
      "Gu signal u transpose 2: torch.Size([2, 512, 10])\n",
      "Gu c zeros: torch.Size([512, 10])\n",
      "----------Gu F Linear:----------\n",
      "Gu part1 shape: torch.Size([512, 10])\n",
      "Gu part2  shape: torch.Size([512, 10])\n",
      "Gu A stacked  shape: torch.Size([10, 10])\n",
      "Gu B stacked  shape: torch.Size([10])\n",
      "Gu input [f] shape: torch.Size([512, 1])\n",
      "Gu Coef c shape: torch.Size([512, 10])\n",
      "----------Gu F Linear:----------\n",
      "Gu part1 shape: torch.Size([512, 10])\n",
      "Gu part2  shape: torch.Size([512, 10])\n",
      "Gu A stacked  shape: torch.Size([10, 10])\n",
      "Gu B stacked  shape: torch.Size([10])\n",
      "Gu input [f] shape: torch.Size([512, 1])\n",
      "Gu Coef c shape: torch.Size([512, 10])\n",
      "Gu Coef c stacked shape: torch.Size([2, 512, 10])\n",
      "------Gu----------\n",
      "gu c tensor([[[ 4.3701e-01,  2.5231e-01, -8.6397e-09,  ...,  1.0486e-08, -8.9336e-09, -1.9513e-10],\n",
      "         [ 2.8740e-01,  1.6593e-01, -5.6820e-09,  ...,  6.8963e-09, -5.8753e-09, -1.2833e-10],\n",
      "         [ 3.3858e-01,  1.9548e-01, -6.6938e-09,  ...,  8.1244e-09, -6.9215e-09, -1.5118e-10],\n",
      "         ...,\n",
      "         [ 4.9409e-01,  2.8527e-01, -9.7683e-09,  ...,  1.1856e-08, -1.0101e-08, -2.2062e-10],\n",
      "         [ 7.8740e-03,  4.5461e-03, -1.5567e-10,  ...,  1.8894e-10, -1.6097e-10, -3.5159e-12],\n",
      "         [ 4.4291e-01,  2.5572e-01, -8.7565e-09,  ...,  1.0628e-08, -9.0543e-09, -1.9777e-10]],\n",
      "\n",
      "        [[ 6.1680e-01,  2.8186e-01, -5.7516e-02,  ...,  1.0008e-08, -1.0936e-08, -4.6444e-09],\n",
      "         [ 4.9081e-01,  2.5913e-01, -1.8781e-02,  ...,  1.0212e-08, -9.4873e-09, -1.6458e-09],\n",
      "         [ 3.0971e-01,  7.2737e-02, -8.2165e-02,  ...,  5.8541e-10, -3.9414e-09, -6.3797e-09],\n",
      "         ...,\n",
      "         [ 6.2992e-01,  2.6026e-01, -8.0111e-02,  ...,  8.4401e-09, -1.0547e-08, -6.3667e-09],\n",
      "         [ 1.5879e-01,  1.3297e-01,  3.1986e-02,  ...,  6.4754e-09, -4.1765e-09,  2.3588e-09],\n",
      "         [ 5.3150e-01,  2.0457e-01, -7.9231e-02,  ...,  6.1517e-09, -8.5606e-09, -6.2558e-09]]])\n",
      "gu c shape  torch.Size([2, 512, 10])\n",
      "-------------Input------------\n",
      "Ramen inputs shape: torch.Size([2, 512])\n",
      "Ramen inputs shape: torch.Size([512, 2, 1])\n",
      "-------------Init------------\n",
      "Ramen coef c shape: (2, 1, 10)\n",
      "-------------Init------------\n",
      "----------Ramen F Linear:----------\n",
      "Ramen part1 shape: torch.Size([2, 2, 10])\n",
      "Ramen part2  shape: (2, 10)\n",
      "Ramen A stacked  shape: (10, 10)\n",
      "Ramen B stacked  shape: (10,)\n",
      "Ramen input [f] shape: torch.Size([2, 1])\n",
      "Ramen Coef  c shape: torch.Size([2, 2, 10])\n",
      "our c_t stacked : (512, 2, 2, 10)\n",
      "------Our----------\n",
      "our c shape (512, 2, 2, 10)\n",
      "our c shape (2, 512, 2, 10)\n",
      "our c shape (2, 512, 10, 2)\n",
      "[[[[ 4.3700787e-01  4.8818898e-01]\n",
      "   [ 2.5230661e-01  2.8185603e-01]\n",
      "   [ 1.6106320e-08  1.7992646e-08]\n",
      "   ...\n",
      "   [ 1.4211115e-08  1.5875480e-08]\n",
      "   [-1.1312932e-08 -1.2637870e-08]\n",
      "   [ 1.4055752e-09  1.5701921e-09]]\n",
      "\n",
      "  [[ 4.8293966e-01  6.2467194e-01]\n",
      "   [ 1.6593137e-01  2.5912571e-01]\n",
      "   [-8.7447256e-02 -7.8643851e-02]\n",
      "   ...\n",
      "   [ 1.2371706e-08  1.7316260e-08]\n",
      "   [-1.2387579e-08 -1.6068155e-08]\n",
      "   [ 3.4513357e-09  3.7161225e-09]]\n",
      "\n",
      "  [[ 5.3149605e-01  5.3149605e-01]\n",
      "   [ 1.5002014e-01  5.8644250e-02]\n",
      "   [-8.6273476e-02 -1.8135040e-01]\n",
      "   ...\n",
      "   [ 6.3390844e-09  6.6183636e-10]\n",
      "   [-5.9591576e-09 -8.4671337e-09]\n",
      "   [-1.9665825e-10 -2.5788824e-09]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.8533005e-01  4.9673295e-01]\n",
      "   [ 1.3168796e-02  1.3204755e-02]\n",
      "   [-4.2433087e-03  7.8105098e-03]\n",
      "   ...\n",
      "   [ 7.7447118e-03 -8.5239448e-03]\n",
      "   [-1.4801836e-03  2.9608731e-03]\n",
      "   [-1.3985963e-02  1.4993753e-03]]\n",
      "\n",
      "  [[ 4.8441288e-01  4.9666244e-01]\n",
      "   [ 1.1535095e-02  1.3031618e-02]\n",
      "   [-6.3443049e-03  7.5099771e-03]\n",
      "   ...\n",
      "   [ 3.6928537e-03 -8.0198180e-03]\n",
      "   [-5.7463623e-03  3.5519544e-03]\n",
      "   [-1.8047823e-02  2.0258275e-03]]\n",
      "\n",
      "  [[ 4.8519537e-01  4.9707568e-01]\n",
      "   [ 1.2840239e-02  1.3693902e-02]\n",
      "   [-4.6644178e-03  8.2819266e-03]\n",
      "   ...\n",
      "   [ 5.9397714e-03 -5.8254274e-03]\n",
      "   [-3.3813510e-03  5.8696717e-03]\n",
      "   [-1.5194929e-02  4.2952416e-03]]]\n",
      "\n",
      "\n",
      " [[[ 4.3700787e-01  4.8818898e-01]\n",
      "   [ 2.5230661e-01  2.8185603e-01]\n",
      "   [ 1.6106320e-08  1.7992646e-08]\n",
      "   ...\n",
      "   [ 1.4211115e-08  1.5875480e-08]\n",
      "   [-1.1312932e-08 -1.2637870e-08]\n",
      "   [ 1.4055752e-09  1.5701921e-09]]\n",
      "\n",
      "  [[ 4.8293966e-01  6.2467194e-01]\n",
      "   [ 1.6593137e-01  2.5912571e-01]\n",
      "   [-8.7447256e-02 -7.8643851e-02]\n",
      "   ...\n",
      "   [ 1.2371706e-08  1.7316260e-08]\n",
      "   [-1.2387579e-08 -1.6068155e-08]\n",
      "   [ 3.4513357e-09  3.7161225e-09]]\n",
      "\n",
      "  [[ 5.3149605e-01  5.3149605e-01]\n",
      "   [ 1.5002014e-01  5.8644250e-02]\n",
      "   [-8.6273476e-02 -1.8135040e-01]\n",
      "   ...\n",
      "   [ 6.3390844e-09  6.6183636e-10]\n",
      "   [-5.9591576e-09 -8.4671337e-09]\n",
      "   [-1.9665825e-10 -2.5788824e-09]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.8533005e-01  4.9673295e-01]\n",
      "   [ 1.3168796e-02  1.3204755e-02]\n",
      "   [-4.2433087e-03  7.8105098e-03]\n",
      "   ...\n",
      "   [ 7.7447118e-03 -8.5239448e-03]\n",
      "   [-1.4801836e-03  2.9608731e-03]\n",
      "   [-1.3985963e-02  1.4993753e-03]]\n",
      "\n",
      "  [[ 4.8441288e-01  4.9666244e-01]\n",
      "   [ 1.1535095e-02  1.3031618e-02]\n",
      "   [-6.3443049e-03  7.5099771e-03]\n",
      "   ...\n",
      "   [ 3.6928537e-03 -8.0198180e-03]\n",
      "   [-5.7463623e-03  3.5519544e-03]\n",
      "   [-1.8047823e-02  2.0258275e-03]]\n",
      "\n",
      "  [[ 4.8519537e-01  4.9707568e-01]\n",
      "   [ 1.2840239e-02  1.3693902e-02]\n",
      "   [-4.6644178e-03  8.2819266e-03]\n",
      "   ...\n",
      "   [ 5.9397714e-03 -5.8254274e-03]\n",
      "   [-3.3813510e-03  5.8696717e-03]\n",
      "   [-1.5194929e-02  4.2952416e-03]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75/252558540.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs)\n",
      "/tmp/ipykernel_75/252558540.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"Ramen part1 shape:\", F.linear(torch.tensor(c_t).float(), torch.tensor(A[t])).shape)\n",
      "/tmp/ipykernel_75/252558540.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Shape mismatch between target torch.Size([2, 512, 10]) and computed coefficent matrix (2, 512, 10, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Gu ck [length L, batch size, input size, size of N]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# our shoudl look like [batch_size, L , input size, size N]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtest_hippo_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[143], line 19\u001b[0m, in \u001b[0;36mtest_hippo_operator\u001b[0;34m(N, batch_size, data_size, input_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#our_c = our_c.squeeze(-1)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(our_c)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m gu_c\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m==\u001b[39mour_c\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch between target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgu_c\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and computed coefficent matrix \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mour_c\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape between target and computed coefficen matrix are equal:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgu_c\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m==\u001b[39mour_c\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(gu_c, np\u001b[38;5;241m.\u001b[39mfloat32(our_c), rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between target and computed coefficent values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Shape mismatch between target torch.Size([2, 512, 10]) and computed coefficent matrix (2, 512, 10, 2)."
     ]
    }
   ],
   "source": [
    "# Gu ck [length L, batch size, input size, size of N]\n",
    "# our shoudl look like [batch_size, L , input size, size N]\n",
    "test_hippo_operator(N=10, batch_size = 2, data_size=512, input_size=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Hippo reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our c shape (512, 2, 1, 10)\n",
    "our c shape (2, 512, 1, 10)\n",
    "our c shape (2, 512, 10, 1)\n",
    "\n",
    "\n",
    "gu c shape  torch.Size([2, 512, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hippo_reconstruct(N=2, batch_size=2, data_size=512, input_size=1, max_length=512):\n",
    "    gu_hippo = HiPPO_LSI(N=N, method=\"legs\", max_length=max_length, discretization=0.5, lambda_n=1.0, alpha=0.5, beta=1.0)\n",
    "    hippo = HIPPO_LEGS(N=N, gbt_alpha=0.5, maxlength=max_length)\n",
    "    inp = gen_batch(batch_size = batch_size, data_size=data_size, input_size=input_size)\n",
    "    \n",
    "    gu_inp = inp\n",
    "    _, B = hippo.get_A_and_B(N=N)\n",
    "    GBTA, GBTB = hippo.get_stacked_GBT()\n",
    "    gu_c = gu_hippo(gu_inp, fast=False)\n",
    "    our_c = hippo.discrete_hippo_operator(A=GBTA, B=GBTB, inputs=inp, c_t=None)\n",
    "    gu_recon = gu_hippo.reconstruct(gu_c)\n",
    "    our_recon = hippo.reconstruct(our_c, B)\n",
    "    \n",
    "    assert gu_recon.shape==our_recon.shape, f\"Shape mismatch between target {gu_recon.shape} and computed reconstruction matrix {our_recon.shape}.\"\n",
    "    print(f\"Shape between target and computed reconstruction matrix is equal:\\n{gu_recon.shape==our_recon.shape}\")\n",
    "    \n",
    "    assert np.allclose(gu_recon, np.float32(our_recon), rtol=1e-04, atol=1e-04), f\"Mismatch between target and computed coefficent values\"\n",
    "    print(f\"Reconstructed values between target and computed are equal:\\n{np.allclose(gu_recon, np.float32(our_recon), rtol=1e-04, atol=1e-04)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "Gu inputs shape: torch.Size([2, 512])\n",
      "Gu L : 2\n",
      "Gu inputs shape unsqueeze : torch.Size([2, 512, 1])\n",
      "Gu signal u transpose : torch.Size([512, 2, 1])\n",
      "Gu self.B_stacked shape : torch.Size([512, 2])\n",
      "Gu self.B_stacked[:L] shape: torch.Size([2, 2])\n",
      "Gu signal u mult self.B_stacked[:L] shape: torch.Size([512, 2, 2])\n",
      "Gu signal u transpose 2: torch.Size([2, 512, 2])\n",
      "Gu c zeros: torch.Size([512, 2])\n",
      "-------------Input------------\n",
      "Ramen inputs shape: torch.Size([2, 512])\n",
      "Ramen inputs shape: torch.Size([512, 2, 1, 1])\n",
      "-------------Init------------\n",
      "Ramen coef c shape: (2, 1, 2)\n",
      "-------------Init------------\n",
      "----------Ramen F Linear:----------\n",
      "Ramen part1 shape: torch.Size([2, 1, 2])\n",
      "Ramen part2  shape: (2, 1, 2)\n",
      "Ramen A stacked  shape: (2, 2)\n",
      "Ramen B stacked  shape: (2,)\n",
      "Ramen input [f] shape: torch.Size([2, 1, 1])\n",
      "Ramen Coef  c shape: torch.Size([2, 1, 2])\n",
      "----------Ramen Reconstruction part:----------\n",
      "Ramen Coefs stacked shape: (2, 512, 1, 2)\n",
      "Ramen Coefs stacked shape: (2, 512, 2, 1)\n",
      "Ramen Eval mat shape: (512, 2)\n",
      "Ramen Coefs stacked shape: (2, 512, 2, 1)\n",
      "Ramen Recon shape: (2, 512, 512, 1)\n",
      "----------------------------------------\n",
      "Shape between target and computed reconstruction matrix is equal:\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_449/121027457.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs)\n",
      "/tmp/ipykernel_449/121027457.py:172: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"Ramen part1 shape:\", F.linear(torch.tensor(c_t).float(), torch.tensor(A[t])).shape)\n",
      "/tmp/ipykernel_449/121027457.py:169: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch between target and computed coefficent values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_hippo_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 17\u001b[0m, in \u001b[0;36mtest_hippo_reconstruct\u001b[0;34m(N, batch_size, data_size, input_size, max_length)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m gu_recon\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m==\u001b[39mour_recon\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch between target \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgu_recon\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and computed reconstruction matrix \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mour_recon\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape between target and computed reconstruction matrix is equal:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgu_recon\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m==\u001b[39mour_recon\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(gu_recon, np\u001b[38;5;241m.\u001b[39mfloat32(our_recon), rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch between target and computed coefficent values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReconstructed values between target and computed are equal:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mallclose(gu_recon, np\u001b[38;5;241m.\u001b[39mfloat32(our_recon), rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-04\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Mismatch between target and computed coefficent values"
     ]
    }
   ],
   "source": [
    "test_hippo_reconstruct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(measure, N, **measure_args):\n",
    "    # Laguerre (translated)\n",
    "    if measure == 'lagt':\n",
    "        b = measure_args.get('beta', 1.0)\n",
    "        A = np.eye(N) / 2 - np.tril(np.ones((N, N)))\n",
    "        B = b * np.ones((N, 1))\n",
    "    # Legendre (translated)\n",
    "    elif measure == 'legt':\n",
    "        Q = np.arange(N, dtype=np.float64)\n",
    "        R = (2*Q + 1) ** .5\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "        A = R[:, None] * np.where(i < j, (-1.)**(i-j), 1) * R[None, :]\n",
    "        B = R[:, None]\n",
    "        A = -A\n",
    "    # Legendre (scaled)\n",
    "    elif measure == 'legs':\n",
    "        q = np.arange(N, dtype=np.float64)\n",
    "        col, row = np.meshgrid(q, q)\n",
    "        r = 2 * q + 1\n",
    "        M = -(np.where(row >= col, r, 0) - np.diag(q))\n",
    "        T = np.sqrt(np.diag(2 * q + 1))\n",
    "        A = T @ M @ np.linalg.inv(T)\n",
    "        B = np.diag(T)[:, None]\n",
    "        B = B.copy() # Otherwise \"UserWarning: given NumPY array is not writeable...\" after torch.as_tensor(B)\n",
    "    elif measure == 'fourier':\n",
    "        freqs = np.arange(N//2)\n",
    "        d = np.stack([np.zeros(N//2), freqs], axis=-1).reshape(-1)[1:]\n",
    "        A = 2*np.pi*(-np.diag(d, 1) + np.diag(d, -1))\n",
    "        B = np.zeros(N)\n",
    "        B[0::2] = 2\n",
    "        B[0] = 2**.5\n",
    "        A = A - B[:, None] * B[None, :]\n",
    "        # A = A - np.eye(N)\n",
    "        B *= 2**.5\n",
    "        B = B[:, None]\n",
    "\n",
    "    return A, B\n",
    "\n",
    "class HiPPOScale(nn.Module):\n",
    "    \"\"\" Vanilla HiPPO-LegS model (scale invariant instead of time invariant) \"\"\"\n",
    "    def __init__(self, N, method='legs', max_length=1024, discretization='bilinear'):\n",
    "        \"\"\"\n",
    "        max_length: maximum sequence length\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        A, B = transition(method, N)\n",
    "        B = B.squeeze(-1)\n",
    "        A_stacked = np.empty((max_length, N, N), dtype=A.dtype)\n",
    "        B_stacked = np.empty((max_length, N), dtype=B.dtype)\n",
    "        for t in range(1, max_length + 1):\n",
    "            At = A / t\n",
    "            Bt = B / t\n",
    "            if discretization == 'forward':\n",
    "                A_stacked[t - 1] = np.eye(N) + At\n",
    "                B_stacked[t - 1] = Bt\n",
    "            elif discretization == 'backward':\n",
    "                A_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, np.eye(N), lower=True)\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, Bt, lower=True)\n",
    "            elif discretization == 'bilinear':\n",
    "                A_stacked[t - 1] = la.solve_triangular(np.eye(N) - At / 2, np.eye(N) + At / 2, lower=True)\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At / 2, Bt, lower=True)\n",
    "            else: # ZOH\n",
    "                A_stacked[t - 1] = la.expm(A * (math.log(t + 1) - math.log(t)))\n",
    "                B_stacked[t - 1] = la.solve_triangular(A, A_stacked[t - 1] @ B - B, lower=True)\n",
    "        self.register_buffer('A_stacked', torch.Tensor(A_stacked)) # (max_length, N, N)\n",
    "        self.register_buffer('B_stacked', torch.Tensor(B_stacked)) # (max_length, N)\n",
    "\n",
    "        vals = np.linspace(0.0, 1.0, max_length)\n",
    "        self.eval_matrix = torch.Tensor((B[:, None] * ss.eval_legendre(np.arange(N)[:, None], 2 * vals - 1)).T  )\n",
    "\n",
    "    def forward(self, inputs, fast=False):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "        # batched input signal has shape [batchsize, maxlength]\n",
    "        L = inputs.shape[1]\n",
    "\n",
    "        print(\"-------------Input------------\")\n",
    "        print(\"inputs shape:\", inputs.shape)\n",
    "        inputs = inputs.T\n",
    "        print(\"inputs shape:\", inputs.shape)\n",
    "        inputs = inputs.unsqueeze(-1).unsqueeze(-1)\n",
    "        print(\"inputs shape:\", inputs.shape)\n",
    "        print(\"-------------Input------------\")\n",
    "        u = torch.transpose(inputs, 0, -2)\n",
    "        print(\"-------------Mul u * B------------\")\n",
    "        print(\"U shape:\",np.array(u).shape)\n",
    "        print(\"self.B_stacked[:L]:\",self.B_stacked[:L].shape)\n",
    "        u = u * self.B_stacked[:L]\n",
    "        u = torch.transpose(u, 0, -2) # (length, ..., N)\n",
    "\n",
    "        if fast:\n",
    "            result = unroll.variable_unroll_matrix(self.A_stacked[:L], u)\n",
    "            return result\n",
    "\n",
    "        # c = torch.zeros(u.shape[1:]).to(inputs)\n",
    "        c = torch.zeros(inputs.shape[1], 1, (self.N)).to(inputs)\n",
    "        print(\"-------------Init------------\", c.shape)\n",
    "        print(\"Coef c shape:\", c.shape)\n",
    "        print(\"-------------Init------------\", c.shape)\n",
    "        cs = []\n",
    "        switch = True\n",
    "        for t, f in enumerate(inputs):\n",
    "            # c = F.linear(c, self.A_stacked[t]) + self.B_stacked[t] * f\n",
    "            c = F.linear(c, self.A_stacked[t]) + torch.mul(self.B_stacked[t], f)\n",
    "            if switch == True:\n",
    "                (\"----------F Linear:----------\")\n",
    "                print(\"part1 shape:\", F.linear(c, self.A_stacked[t]).shape)\n",
    "                # print(\"part2  shape:\", (torch.mul(self.B_stacked[t] * f).shape)\n",
    "                print(\"part2  shape:\",  torch.mul(self.B_stacked[t], f).shape)\n",
    "                print(\"A stacked  shape:\", self.A_stacked[t].shape)\n",
    "                print(\"B stacked  shape:\", self.B_stacked[t].shape)\n",
    "                print(\"input [f] shape:\", f.shape)\n",
    "                print(\"Coef  c shape:\", c.shape)\n",
    "                print(\"----------------------------------------\")\n",
    "                switch = False\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        print(\"----------Reconstruction part:----------\")\n",
    "        print(\"Eval mat shape:\", self.eval_matrix.shape)\n",
    "        print(\"Coefs stacked shape:\", c.shape)\n",
    "        \n",
    "        # If clause for supporting use of direct raw signal \n",
    "        # with no batch information of shape [maxlength]\n",
    "        \n",
    "        # If clause for supporting use of batched raw signal \n",
    "        # with batch information of shape [batchsize, maxlength] \n",
    "        if len(c.shape) == 4:\n",
    "            # c shape from: [maxlength, batchsize, 1, N_coeffs]\n",
    "            # 1st move to: [batchsize, maxlength, 1, N_coeffs]\n",
    "            # 2nd move to: [batchsize, maxlength, N_coeffs, 1]\n",
    "            c = torch.moveaxis(c, 0, 1)\n",
    "            print(\"Coefs stacked shape:\", c.shape)\n",
    "            c = torch.moveaxis(c, 2, 3)\n",
    "            print(\"Coefs stacked shape:\", c.shape)\n",
    "        a = self.eval_matrix.to(c) @ c #.unsqueeze(-1)\n",
    "        stacked = self.B_stacked\n",
    "\n",
    "        return a, c\n",
    "\n",
    "### Synthetic data generation\n",
    "\n",
    "def whitesignal(period, dt, freq, rms=0.5, batch_shape=()):\n",
    "    \"\"\"\n",
    "    Produces output signal of length period / dt, band-limited to frequency freq\n",
    "    Output shape (*batch_shape, period/dt)\n",
    "    Adapted from the nengo library\n",
    "    \"\"\"\n",
    "\n",
    "    if freq is not None and freq < 1. / period:\n",
    "        raise ValueError(f\"Make ``{freq=} >= 1. / {period=}`` to produce a non-zero signal\",)\n",
    "\n",
    "    nyquist_cutoff = 0.5 / dt\n",
    "    if freq > nyquist_cutoff:\n",
    "        raise ValueError(f\"{freq} must not exceed the Nyquist frequency for the given dt ({nyquist_cutoff:0.3f})\")\n",
    "\n",
    "    n_coefficients = int(np.ceil(period / dt / 2.))\n",
    "    shape = batch_shape + (n_coefficients + 1,)\n",
    "    sigma = rms * np.sqrt(0.5)\n",
    "    coefficients = 1j * np.random.normal(0., sigma, size=shape)\n",
    "    coefficients[..., -1] = 0.\n",
    "    coefficients += np.random.normal(0., sigma, size=shape)\n",
    "    coefficients[..., 0] = 0.\n",
    "\n",
    "    set_to_zero = np.fft.rfftfreq(2 * n_coefficients, d=dt) > freq\n",
    "    coefficients *= (1-set_to_zero)\n",
    "    power_correction = np.sqrt(1. - np.sum(set_to_zero, dtype=float) / n_coefficients)\n",
    "    if power_correction > 0.: coefficients /= power_correction\n",
    "    coefficients *= np.sqrt(2 * n_coefficients)\n",
    "    signal = np.fft.irfft(coefficients, axis=-1)\n",
    "    signal = signal - signal[..., :1]  # Start from 0\n",
    "    return signal\n",
    "\n",
    "\n",
    "def reconstruct(T, dt, N, freq, vals, u):\n",
    "    \n",
    "    #vals = np.arange(0.0, T, dt)\n",
    "\n",
    "    #u = whitesignal(T, dt, freq=freq)\n",
    "    u = torch.tensor(u, dtype=torch.float)\n",
    "    u = u.to(device)\n",
    "\n",
    "    # Linear Time Invariant (LTI) methods x' = Ax + Bu\n",
    "    lti_methods = [\n",
    "        'legs',\n",
    "        'legt',\n",
    "        'fourier',\n",
    "    ]\n",
    "\n",
    "    # Original HiPPO-LegS, which uses time-varying SSM x' = 1/t [ Ax + Bu]\n",
    "    # we call this \"linear scale invariant\"\n",
    "    lsi_methods = ['legs']\n",
    "    for method in lsi_methods:\n",
    "        hippo = HiPPOScale(N=N, method=method, max_length=int(T/dt)).to(device)\n",
    "        #u_hippo = hippo.reconstruct(hippo(u))[-1].cpu()\n",
    "        #u_hippo_all  = hippo.reconstruct(hippo(u)).cpu()\n",
    "        u_hippo = hippo.reconstruct(hippo(u))[0][-1].cpu()\n",
    "        u_hippo_all  = hippo.reconstruct(hippo(u))[0].cpu()\n",
    "        coeffs_copy = hippo.reconstruct(hippo(u))[1].cpu()\n",
    "        \n",
    "    return u, u_hippo, u_hippo_all, vals, coeffs_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "Ramen inputs shape: torch.Size([1, 3000])\n",
      "Ramen inputs shape: torch.Size([3000, 1, 1, 1])\n",
      "-------------Init------------\n",
      "Ramen coef c shape: (1, 1, 64)\n",
      "-------------Init------------\n",
      "----------Ramen F Linear:----------\n",
      "Ramen part1 shape: torch.Size([1, 1, 64])\n",
      "Ramen part2  shape: (1, 1, 64)\n",
      "Ramen A stacked  shape: (64, 64)\n",
      "Ramen B stacked  shape: (64,)\n",
      "Ramen input [f] shape: torch.Size([1, 1, 1])\n",
      "Ramen Coef  c shape: torch.Size([1, 1, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75/466675276.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs)\n",
      "/tmp/ipykernel_75/466675276.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"Ramen part1 shape:\", F.linear(torch.tensor(c_t).float(), torch.tensor(A[t])).shape)\n",
      "/tmp/ipykernel_75/466675276.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our c_t stacked : (3000, 1, 1, 64)\n",
      "----------Ramen Reconstruction part:----------\n",
      "Ramen Coefs stacked shape: (1, 3000, 1, 64)\n",
      "Ramen Coefs stacked shape: (1, 3000, 64, 1)\n",
      "Ramen Eval mat shape: (3000, 64)\n",
      "Ramen Coefs stacked shape: (1, 3000, 64, 1)\n",
      "Ramen Recon shape: (1, 3000, 3000, 1)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hippoour = HIPPO_LEGS(N=64, gbt_alpha=0.5, maxlength=3000)\n",
    "_, B = hippoour.get_A_and_B(N=64)\n",
    "GBTA, GBTB = hippoour.get_stacked_GBT()\n",
    "our_c = hippoour.discrete_hippo_operator(A=GBTA, B=GBTB, inputs=sig, c_t=None)\n",
    "our_recon = hippoour.reconstruct(our_c, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation 1 batch dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "inputs shape: torch.Size([1, 3000])\n",
      "inputs shape: torch.Size([3000, 1])\n",
      "inputs shape: torch.Size([3000, 1, 1, 1])\n",
      "-------------Input------------\n",
      "-------------Mul u * B------------\n",
      "U shape: (1, 1, 3000, 1)\n",
      "self.B_stacked[:L]: torch.Size([3000, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "Coef c shape: torch.Size([1, 1, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "part1 shape: torch.Size([1, 1, 64])\n",
      "part2  shape: torch.Size([1, 1, 64])\n",
      "A stacked  shape: torch.Size([64, 64])\n",
      "B stacked  shape: torch.Size([64])\n",
      "input [f] shape: torch.Size([1, 1, 1])\n",
      "Coef  c shape: torch.Size([1, 1, 64])\n",
      "----------------------------------------\n",
      "----------Reconstruction part:----------\n",
      "Eval mat shape: torch.Size([3000, 64])\n",
      "Coefs stacked shape: torch.Size([3000, 1, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 64, 1])\n",
      "-------------Input------------\n",
      "inputs shape: torch.Size([1, 3000])\n",
      "inputs shape: torch.Size([3000, 1])\n",
      "inputs shape: torch.Size([3000, 1, 1, 1])\n",
      "-------------Input------------\n",
      "-------------Mul u * B------------\n",
      "U shape: (1, 1, 3000, 1)\n",
      "self.B_stacked[:L]: torch.Size([3000, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "Coef c shape: torch.Size([1, 1, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "part1 shape: torch.Size([1, 1, 64])\n",
      "part2  shape: torch.Size([1, 1, 64])\n",
      "A stacked  shape: torch.Size([64, 64])\n",
      "B stacked  shape: torch.Size([64])\n",
      "input [f] shape: torch.Size([1, 1, 1])\n",
      "Coef  c shape: torch.Size([1, 1, 64])\n",
      "----------------------------------------\n",
      "----------Reconstruction part:----------\n",
      "Eval mat shape: torch.Size([3000, 64])\n",
      "Coefs stacked shape: torch.Size([3000, 1, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 64, 1])\n",
      "-------------Input------------\n",
      "inputs shape: torch.Size([1, 3000])\n",
      "inputs shape: torch.Size([3000, 1])\n",
      "inputs shape: torch.Size([3000, 1, 1, 1])\n",
      "-------------Input------------\n",
      "-------------Mul u * B------------\n",
      "U shape: (1, 1, 3000, 1)\n",
      "self.B_stacked[:L]: torch.Size([3000, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "Coef c shape: torch.Size([1, 1, 64])\n",
      "-------------Init------------ torch.Size([1, 1, 64])\n",
      "part1 shape: torch.Size([1, 1, 64])\n",
      "part2  shape: torch.Size([1, 1, 64])\n",
      "A stacked  shape: torch.Size([64, 64])\n",
      "B stacked  shape: torch.Size([64])\n",
      "input [f] shape: torch.Size([1, 1, 1])\n",
      "Coef  c shape: torch.Size([1, 1, 64])\n",
      "----------------------------------------\n",
      "----------Reconstruction part:----------\n",
      "Eval mat shape: torch.Size([3000, 64])\n",
      "Coefs stacked shape: torch.Size([3000, 1, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 1, 64])\n",
      "Coefs stacked shape: torch.Size([1, 3000, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "vals = np.arange(0.0, 3, 1e-3)\n",
    "np.random.seed(1)\n",
    "u = whitesignal(3, 1e-3, 3.0, batch_shape=(1,))\n",
    "sig, recon, recon_all_t, values, cfs = reconstruct(T=3, dt=1e-3, N=64, freq=3.0, vals = vals, u = u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "Ramen inputs shape: (1, 3000)\n",
      "Ramen inputs shape: torch.Size([3000, 1, 1])\n",
      "-------------Init------------\n",
      "Ramen coef c shape: (1, 1, 64)\n",
      "-------------Init------------\n",
      "----------Ramen F Linear:----------\n",
      "Ramen part1 shape: torch.Size([1, 1, 64])\n",
      "Ramen part2  shape: (1, 64)\n",
      "Ramen A stacked  shape: (64, 64)\n",
      "Ramen B stacked  shape: (64,)\n",
      "Ramen input [f] shape: torch.Size([1, 1])\n",
      "Ramen Coef  c shape: torch.Size([1, 1, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75/252558540.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(\"Ramen part1 shape:\", F.linear(torch.tensor(c_t).float(), torch.tensor(A[t])).shape)\n",
      "/tmp/ipykernel_75/252558540.py:170: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c_t = F.linear(torch.tensor(c_t).float(), torch.tensor(A[t]).float()) + np.squeeze(B[t], -1) * f_t.numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our c_t stacked : (3000, 1, 1, 64)\n",
      "----------Ramen Reconstruction part:----------\n",
      "Ramen Coefs stacked shape: (1, 3000, 1, 64)\n",
      "Ramen Coefs stacked shape: (1, 3000, 64, 1)\n",
      "Ramen Eval mat shape: (3000, 64)\n",
      "Ramen Coefs stacked shape: (1, 3000, 64, 1)\n",
      "Ramen Recon shape: (1, 3000, 3000, 1)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vals = np.arange(0.0, 3, 1e-3)\n",
    "np.random.seed(1)\n",
    "our_hippo = HIPPO_LEGS(N=64, gbt_alpha=0.5, maxlength=3000)\n",
    "u = whitesignal(3, 1e-3, 3.0, batch_shape=(1,))\n",
    "coeffs, our_recon = our_hippo(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f13041c7310>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#vals = np.arange(0.0, 3, 1e-3)\n",
    "plt.plot(values[-len(sig[0]):], sig[0], label='target',linewidth=3,)\n",
    "#plt.plot(values[-len(recon[:,-1,0]):], recon[:,-1,0], linestyle='--', label='recon', dashes=(5, 5))\n",
    "plt.plot(values[-len(our_recon[0][-1]):], our_recon[0][-1], linestyle='-', label='our recon', dashes=(5, 10))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3000, 64, 1])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1, 1, 64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefs stacked shape: (1, 3000, 1, 64)\n",
      "Coefs stacked shape: (1, 3000, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "coeffs_out = np.moveaxis(coeffs, 0, 1)\n",
    "print(\"Coefs stacked shape:\", coeffs_out.shape)\n",
    "coeffs_out = np.moveaxis(coeffs_out, 2, 3)\n",
    "print(\"Coefs stacked shape:\", coeffs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00],\n",
       "          [ 0.0000e+00]],\n",
       "\n",
       "         [[ 1.0442e-03],\n",
       "          [ 1.2057e-03],\n",
       "          [ 6.6711e-04],\n",
       "          ...,\n",
       "          [-2.8104e-19],\n",
       "          [ 2.7685e-19],\n",
       "          [-2.7278e-19]],\n",
       "\n",
       "         [[ 2.2363e-03],\n",
       "          [ 2.1514e-03],\n",
       "          [ 5.5474e-04],\n",
       "          ...,\n",
       "          [-9.4629e-19],\n",
       "          [ 9.5765e-19],\n",
       "          [-6.2370e-19]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3436e-01],\n",
       "          [-1.1830e-01],\n",
       "          [ 1.4471e-02],\n",
       "          ...,\n",
       "          [-3.3120e-06],\n",
       "          [ 3.3317e-06],\n",
       "          [-3.3852e-06]],\n",
       "\n",
       "         [[-1.3432e-01],\n",
       "          [-1.1814e-01],\n",
       "          [ 1.4706e-02],\n",
       "          ...,\n",
       "          [-3.3105e-06],\n",
       "          [ 3.3298e-06],\n",
       "          [-3.3852e-06]],\n",
       "\n",
       "         [[-1.3427e-01],\n",
       "          [-1.1799e-01],\n",
       "          [ 1.4941e-02],\n",
       "          ...,\n",
       "          [-3.3097e-06],\n",
       "          [ 3.3264e-06],\n",
       "          [-3.3842e-06]]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00]],\n",
       "\n",
       "        [[ 1.0441997e-03],\n",
       "         [ 1.2057379e-03],\n",
       "         [ 6.6711480e-04],\n",
       "         ...,\n",
       "         [ 9.3220764e-11],\n",
       "         [-8.0199104e-11],\n",
       "         [ 6.6280301e-11]],\n",
       "\n",
       "        [[ 2.2362981e-03],\n",
       "         [ 2.1514497e-03],\n",
       "         [ 5.5474316e-04],\n",
       "         ...,\n",
       "         [ 1.3331677e-10],\n",
       "         [-2.5506519e-10],\n",
       "         [ 3.2492781e-10]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.3435808e-01],\n",
       "         [-1.1829770e-01],\n",
       "         [ 1.4471100e-02],\n",
       "         ...,\n",
       "         [-3.3927831e-06],\n",
       "         [ 3.5822402e-06],\n",
       "         [-3.6629956e-06]],\n",
       "\n",
       "        [[-1.3431503e-01],\n",
       "         [-1.1814430e-01],\n",
       "         [ 1.4705439e-02],\n",
       "         ...,\n",
       "         [-3.3917993e-06],\n",
       "         [ 3.5789706e-06],\n",
       "         [-3.6622514e-06]],\n",
       "\n",
       "        [[-1.3427113e-01],\n",
       "         [-1.1798958e-01],\n",
       "         [ 1.4941187e-02],\n",
       "         ...,\n",
       "         [-3.3909371e-06],\n",
       "         [ 3.5766875e-06],\n",
       "         [-3.6629021e-06]]]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(cfs, coeffs_out,  rtol=1e-04, atol=1e-04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation 2 batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Input------------\n",
      "inputs shape: torch.Size([2, 3000])\n",
      "inputs shape: torch.Size([3000, 2])\n",
      "inputs shape: torch.Size([3000, 2, 1, 1])\n",
      "-------------Input------------\n",
      "-------------Mul u * B------------\n",
      "U shape: (1, 2, 3000, 1)\n",
      "self.B_stacked[:L]: torch.Size([3000, 64])\n",
      "-------------Init------------ torch.Size([2, 1, 64])\n",
      "Coef c shape: torch.Size([2, 1, 64])\n",
      "-------------Init------------ torch.Size([2, 1, 64])\n",
      "part1 shape: torch.Size([2, 1, 64])\n",
      "part2  shape: torch.Size([2, 1, 64])\n",
      "A stacked  shape: torch.Size([64, 64])\n",
      "B stacked  shape: torch.Size([64])\n",
      "input [f] shape: torch.Size([2, 1, 1])\n",
      "Coef  c shape: torch.Size([2, 1, 64])\n",
      "----------------------------------------\n",
      "----------Reconstruction part:----------\n",
      "Eval mat shape: torch.Size([3000, 64])\n",
      "Coefs stacked shape: torch.Size([3000, 2, 1, 64])\n",
      "Coefs stacked shape: torch.Size([2, 3000, 1, 64])\n",
      "Coefs stacked shape: torch.Size([2, 3000, 64, 1])\n",
      "Recon shape: torch.Size([2, 3000, 3000, 1])\n",
      "----------------------------------------\n",
      "-------------Input------------\n",
      "inputs shape: torch.Size([2, 3000])\n",
      "inputs shape: torch.Size([3000, 2])\n",
      "inputs shape: torch.Size([3000, 2, 1, 1])\n",
      "-------------Input------------\n",
      "-------------Mul u * B------------\n",
      "U shape: (1, 2, 3000, 1)\n",
      "self.B_stacked[:L]: torch.Size([3000, 64])\n",
      "-------------Init------------ torch.Size([2, 1, 64])\n",
      "Coef c shape: torch.Size([2, 1, 64])\n",
      "-------------Init------------ torch.Size([2, 1, 64])\n",
      "part1 shape: torch.Size([2, 1, 64])\n",
      "part2  shape: torch.Size([2, 1, 64])\n",
      "A stacked  shape: torch.Size([64, 64])\n",
      "B stacked  shape: torch.Size([64])\n",
      "input [f] shape: torch.Size([2, 1, 1])\n",
      "Coef  c shape: torch.Size([2, 1, 64])\n",
      "----------------------------------------\n",
      "----------Reconstruction part:----------\n",
      "Eval mat shape: torch.Size([3000, 64])\n",
      "Coefs stacked shape: torch.Size([3000, 2, 1, 64])\n",
      "Coefs stacked shape: torch.Size([2, 3000, 1, 64])\n",
      "Coefs stacked shape: torch.Size([2, 3000, 64, 1])\n",
      "Recon shape: torch.Size([2, 3000, 3000, 1])\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "vals = np.arange(0.0, 3, 1e-3)\n",
    "np.random.seed(0)\n",
    "u = whitesignal(3, 1e-3, 3.0, batch_shape=(2,))\n",
    "sig, recon, recon_all_t, values = reconstruct(T=3, dt=1e-3, N=64, freq=3.0, vals=vals, u=u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 3000, 1])\n",
      "torch.Size([2, 3000, 3000, 1])\n",
      "torch.Size([3000, 3000, 1])\n",
      "torch.Size([3000, 1])\n"
     ]
    }
   ],
   "source": [
    "print(recon.shape)\n",
    "print(recon_all_t.shape)\n",
    "print(recon_all_t[0].shape)\n",
    "print(recon_all_t[0][0].shape)\n",
    "# print(recon_all_t[0][:,-1,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(sig[\u001b[38;5;241m1\u001b[39m]):], sig[\u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m,linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#plt.plot(values[-len(recon_all_t[1][-1]):], recon_all_t[1][-1], linestyle='--', label='recon', dashes=(5, 1))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "vals = np.arange(0.0, 3, 1e-3)\n",
    "plt.plot(values[-len(sig[1]):], sig[1], label='target',linewidth=3,)\n",
    "#plt.plot(values[-len(recon_all_t[1][-1]):], recon_all_t[1][-1], linestyle='--', label='recon', dashes=(5, 1))\n",
    "plt.plot(vals[-len(our_recon):], gu_hippo_recon, label='our', dashes=(5, 5))\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "616abfd6b1e11a599364f0d5228ada514baf1d2a8611f9274dc002b78190c46b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
