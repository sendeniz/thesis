{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19327,"status":"ok","timestamp":1682285643817,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-120},"id":"Opmfrf6pD0xj","outputId":"0ea4296c-3cfd-4b1d-b9e3-a0dc2faceb00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":221,"status":"ok","timestamp":1682285675966,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-120},"id":"efu4fPPTECE4","outputId":"78145033-950b-418a-87b8-2bc48319a34b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/rnns\n"]}],"source":["%cd gdrive/MyDrive/rnns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":216,"status":"ok","timestamp":1679424693125,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-60},"id":"5o6GaFv9GsRh","outputId":"60b5abed-b157-48f1-ee1c-60ec8545f5fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpts  HiPPO.ipynb  __pycache__\t   results\trnn.py\t\ttrain.py\n","data  __init__.py  ramen_hippo.py  rnncells.py\tterminal.ipynb\tutils.py\n"]}],"source":["!ls"]},{"cell_type":"markdown","source":[],"metadata":{"id":"bNcAjsgiJ2w-"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6664,"status":"ok","timestamp":1682286792816,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-120},"id":"PwRyLgoHyaqD","outputId":"bc82abe7-ae05-4b76-e3f9-2c0865275706"},"outputs":[{"output_type":"stream","name":"stdout","text":["Simple RNN size test: passed.\n","Gru RNN size test: passed.\n","LSTM RNN size test: passed.\n"]}],"source":["!python rnn.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8JtOJ-a63cz","outputId":"0b6ba36e-95c5-481b-881b-12d2b994e921"},"outputs":[{"output_type":"stream","name":"stdout","text":["Simple RNN size test: passed.\n","Gru RNN size test: passed.\n","LSTM RNN size test: passed.\n","Run 1/5: LSTM RNN initalised with 2 layers and 64 number of hidden neurons.\n","Epoch:1   Train[Loss:2.2835 Top1 Acc:0.3157  Top5 Acc:0.9027]\n","Epoch:1   Test[Loss:2.2832   Top1 Acc:0.3149   Top5 Acc:0.9045]\n","Epoch:2   Train[Loss:2.0713 Top1 Acc:0.5232  Top5 Acc:0.9262]\n","Epoch:2   Test[Loss:2.0713   Top1 Acc:0.5178   Top5 Acc:0.9211]\n","Epoch:3   Train[Loss:1.9415 Top1 Acc:0.6398  Top5 Acc:0.8663]\n","Epoch:3   Test[Loss:1.9385   Top1 Acc:0.6406   Top5 Acc:0.862]\n","Checkpoint and evaluation at epoch 3 stored\n"]}],"source":["!python train.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"691rhFJG5VOV"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","a = torch.tensor([[ 0.2191, -1.9177,  0.0654,  1.9643,  0.1032,  0.3341, -0.0420,  0.2283,\n","         -0.5080,  1.5319],\n","        [-0.3936, -1.4508, -0.7349,  1.1032, -0.6381,  1.2768, -0.5390, -0.6996,\n","          0.5231,  0.9895],\n","        [ 0.8200, -0.2018, -0.6257,  1.4932, -0.8290,  0.4215,  0.1613, -0.3268,\n","         -0.4961,  0.1400],\n","        [-0.4569, -1.6752, -0.0989,  0.9211,  0.6620,  0.2545, -0.5454, -0.1586,\n","          0.0389,  1.3933]])\n","y = torch.tensor([3, 5, 6, 6])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351,"status":"ok","timestamp":1679229973935,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-60},"id":"FMnSayq25rgy","outputId":"53cb544b-3504-41ee-b562-c4fec6f558d8"},"outputs":[{"data":{"text/plain":["tensor([[0.0637, 0.0075, 0.0546, 0.3649, 0.0567, 0.0715, 0.0491, 0.0643, 0.0308,\n","         0.2368],\n","        [0.0483, 0.0168, 0.0343, 0.2157, 0.0378, 0.2566, 0.0417, 0.0356, 0.1208,\n","         0.1925],\n","        [0.1658, 0.0597, 0.0391, 0.3251, 0.0319, 0.1113, 0.0858, 0.0527, 0.0445,\n","         0.0840],\n","        [0.0453, 0.0134, 0.0649, 0.1798, 0.1388, 0.0923, 0.0415, 0.0611, 0.0744,\n","         0.2884]])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["cp = F.softmax(a, dim = 1)\n","cp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1679229976681,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-60},"id":"WEbhW9u456mM","outputId":"45d13eed-a8df-4df8-f07e-02940543d06f"},"outputs":[{"data":{"text/plain":["tensor([3, 5, 3, 9])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["p = torch.argmax(cp, dim = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1679230233479,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-60},"id":"JpT7kdl66aSJ","outputId":"0062f616-c08c-4a4c-f191-c8dedfe44150"},"outputs":[{"data":{"text/plain":["tensor(0.5000)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":[" sum(y==p) / 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUe9Cv3P7Dg2"},"outputs":[],"source":["def test_top1accuracy(out, target, batch_size):\n","    \"\"\"\n","    Calculates top 1 accuracy.\n","    Input: Output of class probabilities from the neural network (tensor)\n","    and target class predictions (tensor) of shape number of classes by batch size \n","    Output: Top 1 accuracy (float).\n","    \"\"\"\n","    with torch.no_grad():\n","        pred_class = torch.argmax(out, dim = 1)\n","        top1_acc = sum(target==pred_class) / batch_size\n","        return top1_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1679230306101,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-60},"id":"dKdd8sd07GYm","outputId":"78d1dd1a-acd4-4966-da82-a7366c4dd8f5"},"outputs":[{"data":{"text/plain":["tensor(0.5000)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["t = test_top1accuracy(cp, y, 4)\n","t"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1709,"status":"ok","timestamp":1682286051814,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"},"user_tz":-120},"id":"d_vvJTrJNQ-I","outputId":"6bc73a43-5bd8-45e2-fc5a-47ef4c2e7ac7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Size test: passed.\n"]}],"source":["import torch\n","from torch import nn\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","import numpy as np\n","\n","class LstmCell(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(LstmCell, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","\n","        self.input2hidden = nn.Linear(input_size, hidden_size)\n","        self.hidden2hidden = nn.Linear(hidden_size, hidden_size)\n","        self.init_weights_normal()\n","    \n","    def init_weights_normal(self):\n","        # iterate over parameters or weights theta\n","        # and initalise them with a normal centered at 0 with 0.02 spread.\n","        for weight in self.parameters():\n","            weight.data.normal_(0, 0.02)\n","\n","    def forward(self, input, hidden_state = None):\n","        '''\n","        Inputs: input (torch tensor) of shape [batchsize, input_size]\n","                hidden state (torch tensor) of shape [batchsize, hiddensize]\n","        Output: output (torch tensor) of shape [batchsize, hiddensize]\n","        '''\n","        if hidden_state is None:\n","            hidden_state = torch.zeros(input.shape[0], self.hidden_size).to(device)\n","            hidden_state = (hidden_state, hidden_state)\n","\n","        hidden_state, previous_cell_state = hidden_state\n","\n","        input_gate = self.input2hidden(input) + self.hidden2hidden(hidden_state)\n","        forget_gate = self.input2hidden(input) + self.hidden2hidden(hidden_state)\n","        cell_gate = self.input2hidden(input) + self.hidden2hidden(hidden_state)\n","        output_gate = self.input2hidden(input) + self.hidden2hidden(hidden_state)\n","\n","\n","        input_gate_activation = torch.sigmoid(input_gate)\n","        forget_gate_activation = torch.sigmoid(forget_gate)\n","        cell_gate_activation = torch.tanh(cell_gate)\n","        output_gate_activation = torch.sigmoid(output_gate)\n","\n","        updated_cell_state = previous_cell_state * forget_gate_activation + input_gate_activation * cell_gate_activation\n","\n","        # output for the hidden\n","        out = output_gate_activation * torch.tanh(updated_cell_state)\n","\n","        return (out, updated_cell_state)\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(LSTM, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.output_size = output_size\n","\n","        self.rnn_cell_list = nn.ModuleList()\n","\n","        self.rnn_cell_list.append(LstmCell(self.input_size,\n","                                            self.hidden_size,\n","                                            ))\n","        for l in range(1, self.num_layers):\n","            self.rnn_cell_list.append(LstmCell(self.hidden_size,\n","                                                self.hidden_size,\n","                                                ))\n","\n","        self.fc = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hx=None):\n","\n","        # Input of shape (batch_size, seqence length , input_size)\n","        #\n","        # Output of shape (batch_size, output_size)\n","\n","        if hx is None:\n","            if torch.cuda.is_available():\n","                h0 =torch.zeros(self.num_layers, input.shape[0], self.hidden_size).to(device)\n","            else:\n","                h0 =torch.zeros(self.num_layers, input.shape[0], self.hidden_size).to(device)\n","        else:\n","             h0 = hx\n","\n","        outs = []\n","\n","        hidden = list()\n","        for layer in range(self.num_layers):\n","            hidden.append((h0[layer, :, :], h0[layer, :, :]))\n","\n","        for t in range(input.size(1)):\n","\n","            for layer in range(self.num_layers):\n","\n","                if layer == 0:\n","                    hidden_l = self.rnn_cell_list[layer](\n","                        input[:, t, :],\n","                        (hidden[layer][0], hidden[layer][1])\n","                        )\n","                else:\n","                    hidden_l = self.rnn_cell_list[layer](\n","                        hidden[layer - 1][0],\n","                        (hidden[layer][0], hidden[layer][1])\n","                        )\n","\n","                hidden[layer] = hidden_l\n","\n","            outs.append(hidden_l[0])\n","\n","        out = outs[-1].squeeze()\n","\n","        out = self.fc(out)\n","\n","        return out\n","\n","def test ():\n","  # batch size, sequence length, input size\n","    model = LSTM(input_size=28*28, hidden_size=128, num_layers=3, output_size=10)\n","    model = model.to(device)\n","    x = torch.randn(64, 28*28)\n","    x = x.unsqueeze(-1)\n","    vals = torch.ones(64, 28*28, 28*28-1) * (28*28)\n","    x = torch.cat([x, vals], dim=-1).to(device)\n","    out = model(x)\n","    xshape = out.shape\n","    return x, xshape\n","\n","testx, xdims = test()\n","print(\"Size test: passed.\")"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}